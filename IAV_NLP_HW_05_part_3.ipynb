{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# загрузка датасета\n",
        "\n",
        "%mkdir dataset\n",
        "%cd dataset\n",
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip\n",
        "!unzip collection5.zip     "
      ],
      "metadata": {
        "id": "uPFPV3L-xDb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install corus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3xEo4GYxTy8",
        "outputId": "da730cf5-9246-4577-8aec-f60d8ae9c9ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: corus in /usr/local/lib/python3.9/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import corus"
      ],
      "metadata": {
        "id": "fepaHj2VxQGf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_ne5\n",
        "\n",
        "dir = 'Collection5/'\n",
        "records = load_ne5(dir)\n",
        "next(records)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyBDY8jixju3",
        "outputId": "b7867867-a6bc-4320-cd0d-b900d494f3e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ne5Markup(\n",
              "    id='1180',\n",
              "    text='\\r\\nЭкс-мэр Волгограда возглавил список ЕР на выборах в гордуму\\r\\n\\r\\n\\r\\nпри этом второе место занял первый вице-премьер правительства региона Роланд Херианов, ранее также упрвлявший городом.\\r\\nПервый зампредседателя правительства Волгоградской области Роман Гребенников, отстраненный от должности мэра Волгограда в 2011 году, возглавил список кандидатов \"Единой России\" на выборах в городскую думу, сообщил РИА Новости представитель регионального отделения партии.\\r\\n\\r\\nВыборы в гордуму Волгограда пройдут в сентябре этого года по смешанной системе. Всего предстоит выбрать 48 депутатов, из которых 24 будут избраны по партийным спискам и столько же по одномандатным округам. Согласно действующему уставу города, депутатам затем предстоит выбрать из своего состава нового главу Волгограда.\\r\\n\\r\\n\"Общегородской список кандидатов и список по одномандатным округам утверждены на 24-й конференции волгоградского регионального отделения партии. Общегородской список возглавил Гребенников, далее за ним идет первый вице-премьер правительства региона Роланд Херианов и депутат областной думы Ирина Гусева\", — сказал собеседник агентства, уточнив, что в общегородском списке всего три кандидата.\\r\\n\\r\\nДанные фамилии в аналогичном порядке назывались еще в мае по итогам праймериз \"Единой России\". Сообщалось, что окончательный список будет сформирован с учетом социологии, консультаций с общественными и партийными организациями.\\r\\n\\r\\nПримечательно, что второй в общегородском списке кандидатов Херианов, как и Гребенников, имеет опыт руководства Волгоградом. С мая 2006 года по май 2007 года он исполнял обязанности главы города, но на выборах мэра в мае 2007 года занял второе место, проиграв Гребенникову.\\r\\n\\r\\nГребенников был отстранен от должности мэра в феврале 2011 года постановлением предыдущего губернатора Анатолия Бровко, который ушел в отставку по собственному желанию в январе 2012 года. В марте этого года Гребенников и Херианов были утверждены первыми заместителями председателя правительства Волгоградской области.',\n",
              "    spans=[Ne5Span(\n",
              "         index='T1',\n",
              "         type='LOC',\n",
              "         start=10,\n",
              "         stop=20,\n",
              "         text='Волгограда'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T2',\n",
              "         type='ORG',\n",
              "         start=38,\n",
              "         stop=40,\n",
              "         text='ЕР'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T3',\n",
              "         type='PER',\n",
              "         start=137,\n",
              "         stop=152,\n",
              "         text='Роланд Херианов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T4',\n",
              "         type='LOC',\n",
              "         start=224,\n",
              "         stop=245,\n",
              "         text='Волгоградской области'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T5',\n",
              "         type='PER',\n",
              "         start=246,\n",
              "         stop=263,\n",
              "         text='Роман Гребенников'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T6',\n",
              "         type='LOC',\n",
              "         start=296,\n",
              "         stop=306,\n",
              "         text='Волгограда'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T7',\n",
              "         type='ORG',\n",
              "         start=349,\n",
              "         stop=362,\n",
              "         text='Единой России'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T8',\n",
              "         type='MEDIA',\n",
              "         start=401,\n",
              "         stop=412,\n",
              "         text='РИА Новости'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T9',\n",
              "         type='LOC',\n",
              "         start=479,\n",
              "         stop=489,\n",
              "         text='Волгограда'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T10',\n",
              "         type='LOC',\n",
              "         start=770,\n",
              "         stop=780,\n",
              "         text='Волгограда'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T11',\n",
              "         type='PER',\n",
              "         start=961,\n",
              "         stop=972,\n",
              "         text='Гребенников'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T12',\n",
              "         type='PER',\n",
              "         start=1034,\n",
              "         stop=1049,\n",
              "         text='Роланд Херианов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T13',\n",
              "         type='PER',\n",
              "         start=1075,\n",
              "         stop=1087,\n",
              "         text='Ирина Гусева'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T14',\n",
              "         type='ORG',\n",
              "         start=1260,\n",
              "         stop=1273,\n",
              "         text='Единой России'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T15',\n",
              "         type='PER',\n",
              "         start=1472,\n",
              "         stop=1480,\n",
              "         text='Херианов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T16',\n",
              "         type='PER',\n",
              "         start=1488,\n",
              "         stop=1499,\n",
              "         text='Гребенников'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T17',\n",
              "         type='LOC',\n",
              "         start=1524,\n",
              "         stop=1535,\n",
              "         text='Волгоградом'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T18',\n",
              "         type='PER',\n",
              "         start=1672,\n",
              "         stop=1684,\n",
              "         text='Гребенникову'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T19',\n",
              "         type='PER',\n",
              "         start=1689,\n",
              "         stop=1700,\n",
              "         text='Гребенников'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T20',\n",
              "         type='PER',\n",
              "         start=1792,\n",
              "         stop=1807,\n",
              "         text='Анатолия Бровко'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T21',\n",
              "         type='PER',\n",
              "         start=1896,\n",
              "         stop=1907,\n",
              "         text='Гребенников'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T22',\n",
              "         type='PER',\n",
              "         start=1910,\n",
              "         stop=1918,\n",
              "         text='Херианов'\n",
              "     ),\n",
              "     Ne5Span(\n",
              "         index='T23',\n",
              "         type='LOC',\n",
              "         start=1984,\n",
              "         stop=2005,\n",
              "         text='Волгоградской области'\n",
              "     )]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install razdel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usn5pWtDx3Sx",
        "outputId": "a00938df-aabb-4367-9227-00da53be17d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: razdel in /usr/local/lib/python3.9/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize"
      ],
      "metadata": {
        "id": "5rBIdLQjx0km"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_docs = []\n",
        "for ix, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ],
      "metadata": {
        "id": "k1qMttK3x8S1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
      ],
      "metadata": {
        "id": "a_dAlJ5Tx_o2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "metadata": {
        "id": "gWCBzG169H53"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "BOKxeRLZ_2o5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection, preprocessing, linear_model\n",
        "\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
        "\n",
        "# labelEncode целевую переменную\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "metadata": {
        "id": "i6Su6ixd9KxA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.apply(len).max(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WBTe8Tj9NF3",
        "outputId": "14751592-1d68-452b-c03a-b52c458b1cab"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
        "\n",
        "train_data = train_data.batch(16)\n",
        "valid_data = valid_data.batch(16)"
      ],
      "metadata": {
        "id": "Rm6lkDvc9PCj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "WuxU9KLc-f9h"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Передаем в сетку только сам токен"
      ],
      "metadata": {
        "id": "xSD9Usf1_Zkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    #ngrams=(1, 3),\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "AbShhzjh-hv5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorize_layer.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF9YJlv7-kBJ",
        "outputId": "e594c281-e2dc-4dd4-ce2b-6cf951ce8f39"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29869"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "\n",
        "class modelNER(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(modelNER, self).__init__()\n",
        "        self.emb = Embedding(vocab_size, embedding_dim)\n",
        "        self.gPool = GlobalMaxPooling1D()\n",
        "        self.fc1 = Dense(300, activation='relu')\n",
        "        self.fc2 = Dense(50, activation='relu')\n",
        "        self.fc3 = Dense(6, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = vectorize_layer(x)\n",
        "        x = self.emb(x)\n",
        "        pool_x = self.gPool(x)\n",
        "        \n",
        "        fc_x = self.fc1(pool_x)\n",
        "        fc_x = self.fc2(fc_x)\n",
        "        \n",
        "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
        "        prob = self.fc3(concat_x)\n",
        "        return prob"
      ],
      "metadata": {
        "id": "6XncCm1f-mTL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "2BPcnzv3-qPz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hd3Dq-VJ-t7D"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z16cxf7f-u7T",
        "outputId": "097392ab-6587-4b4c-bdfe-1388bb980f33"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12430/12430 [==============================] - 63s 5ms/step - loss: 0.2965 - accuracy: 0.9138 - val_loss: 0.2101 - val_accuracy: 0.9394\n",
            "Epoch 2/3\n",
            "12430/12430 [==============================] - 60s 5ms/step - loss: 0.1262 - accuracy: 0.9624 - val_loss: 0.2904 - val_accuracy: 0.8939\n",
            "Epoch 3/3\n",
            "12430/12430 [==============================] - 60s 5ms/step - loss: 0.1100 - accuracy: 0.9655 - val_loss: 0.2285 - val_accuracy: 0.9413\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe037466fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_n = mmodel.predict(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oedYgQUU_rJl",
        "outputId": "3bc5f6c6-206e-40e4-e312-c516614ea03a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4144/4144 [==============================] - 9s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = np.argmax(tf.nn.softmax(predict_n), axis=1)\n",
        "class_preds = encoder.inverse_transform(class_preds)"
      ],
      "metadata": {
        "id": "l_LqzxIfADqZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_y_inv = encoder.inverse_transform(valid_y)"
      ],
      "metadata": {
        "id": "tZib2HXGAfFQ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(valid_y_inv, class_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lXLTp1rAkNL",
        "outputId": "56863996-9c73-4b35-cb64-26b396bb9099"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.91      0.90      0.90      1107\n",
            "         LOC       0.85      0.78      0.82      1144\n",
            "       MEDIA       0.89      0.78      0.83       593\n",
            "         ORG       0.87      0.56      0.68      3402\n",
            "         OUT       0.94      0.99      0.97     54819\n",
            "         PER       0.97      0.72      0.82      5229\n",
            "\n",
            "    accuracy                           0.94     66294\n",
            "   macro avg       0.91      0.79      0.84     66294\n",
            "weighted avg       0.94      0.94      0.94     66294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Передаем в сетку токен и соседей"
      ],
      "metadata": {
        "id": "bN-BplLl_evG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    ngrams=(1, 3),\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "crw2oiht_jOG"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "w0gk8HFWCm8r"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Kx7ATmZFCvgf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BgpzkX_C7Af",
        "outputId": "d89e2441-ac2d-4494-bf20-bec342655669"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12430/12430 [==============================] - 72s 6ms/step - loss: 0.2941 - accuracy: 0.9146 - val_loss: 0.2091 - val_accuracy: 0.9380\n",
            "Epoch 2/3\n",
            "12430/12430 [==============================] - 67s 5ms/step - loss: 0.1254 - accuracy: 0.9626 - val_loss: 0.2466 - val_accuracy: 0.8935\n",
            "Epoch 3/3\n",
            "12430/12430 [==============================] - 66s 5ms/step - loss: 0.1105 - accuracy: 0.9655 - val_loss: 0.2502 - val_accuracy: 0.8828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe036f1d520>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_n13 = mmodel.predict(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFgN3CYlD7yq",
        "outputId": "831b1d6e-6613-4253-f2d5-f76a945b3bc9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4144/4144 [==============================] - 14s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = np.argmax(tf.nn.softmax(predict_n13), axis=1)\n",
        "class_preds = encoder.inverse_transform(class_preds)"
      ],
      "metadata": {
        "id": "c9K9OJIjEBY-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(valid_y_inv, class_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibPgNsHcEG1k",
        "outputId": "149f0a10-7122-4690-a776-d28dfa870400"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.90      0.90      1107\n",
            "         LOC       0.16      0.93      0.28      1144\n",
            "       MEDIA       0.91      0.78      0.84       593\n",
            "         ORG       0.84      0.57      0.68      3402\n",
            "         OUT       0.97      0.92      0.94     54819\n",
            "         PER       0.97      0.72      0.82      5229\n",
            "\n",
            "    accuracy                           0.88     66294\n",
            "   macro avg       0.79      0.80      0.74     66294\n",
            "weighted avg       0.95      0.88      0.91     66294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Передаем в сетку би-граммы"
      ],
      "metadata": {
        "id": "zJcI2A0nEN7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "    return input_data\n",
        "\n",
        "vocab_size = 30000\n",
        "seq_len = 10\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    ngrams=2,\n",
        "    output_sequence_length=seq_len)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_data = train_data.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_data)"
      ],
      "metadata": {
        "id": "xJyUYOmAEJ4p"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel = modelNER()"
      ],
      "metadata": {
        "id": "jiTCY_-_EZcI"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iiWx0qKNEbkX"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mmodel.fit(train_data, validation_data=valid_data, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt4sHPZWEdvi",
        "outputId": "6452f6d4-78da-4c69-9f96-5bba1ecbfd33"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "12430/12430 [==============================] - 75s 6ms/step - loss: 0.2950 - accuracy: 0.9139 - val_loss: 0.2099 - val_accuracy: 0.9396\n",
            "Epoch 2/3\n",
            "12430/12430 [==============================] - 67s 5ms/step - loss: 0.1249 - accuracy: 0.9628 - val_loss: 0.2179 - val_accuracy: 0.9416\n",
            "Epoch 3/3\n",
            "12430/12430 [==============================] - 67s 5ms/step - loss: 0.1095 - accuracy: 0.9657 - val_loss: 0.2220 - val_accuracy: 0.9411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0bde77a60>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_n2 = mmodel.predict(valid_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2XKw4MCEh5-",
        "outputId": "e4cfea34-95fa-4004-dd5e-e6f5a8f26241"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4144/4144 [==============================] - 10s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_preds = np.argmax(tf.nn.softmax(predict_n2), axis=1)\n",
        "class_preds = encoder.inverse_transform(class_preds)"
      ],
      "metadata": {
        "id": "gI-MbhITElkM"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(valid_y_inv, class_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiupF7GdEoHI",
        "outputId": "fbffb88b-29ac-4594-db9e-c0f2760ea951"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    GEOPOLIT       0.90      0.90      0.90      1107\n",
            "         LOC       0.86      0.78      0.82      1144\n",
            "       MEDIA       0.92      0.78      0.84       593\n",
            "         ORG       0.85      0.57      0.68      3402\n",
            "         OUT       0.95      0.99      0.97     54819\n",
            "         PER       0.97      0.72      0.82      5229\n",
            "\n",
            "    accuracy                           0.94     66294\n",
            "   macro avg       0.91      0.79      0.84     66294\n",
            "weighted avg       0.94      0.94      0.94     66294\n",
            "\n"
          ]
        }
      ]
    }
  ]
}